# -*- coding: utf-8 -*-
"""명사기반 핵심어 추출NEW.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-UNPzUPSEXKJl4ZwkfzldXacO2tIFQ1K
"""

# ✅ 1. 필수 설치 (Colab용)
!pip install konlpy

# ✅ 2. 라이브러리 임포트
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from konlpy.tag import Okt
import re

# ✅ 3. 데이터 로딩
df_noun = pd.read_csv("고유명사_추출결과.csv")
df_overview = pd.read_csv("개요만.csv")
df_noun["고유명사"] = df_noun["고유명사"].apply(eval)  # 리스트로 변환
df = pd.merge(df_noun, df_overview, on="숙소명", how="left")

# 불용어 리스트
korean_stopwords = {
    "은", "는", "이", "가", "을", "를", "에", "에서", "에게", "한테", "으로", "로", "과", "와", "랑", "도", "만",
    "또한", "그리고", "그러나", "즉", "예를", "들면", "따라서", "때문에",
    "자신", "것", "수", "중", "더", "정도", "같은", "이런", "그런", "저런",
    "좀", "요", "아주", "너무", "많이", "잘", "꼭", "혹시", "정말", "진짜", "다소", "대체로", "각각", "대부분",
    "숙소", "호텔", "객실", "이용", "예약", "시설", "서비스", "위치", "전망", "가격", "가성비",
    "가능", "가장", "가족", "같은", "곳에", "없는", "없이", "있는", "좋은", "차로", "마다", "만큼", "부터", "부터는", "밖에",
    "보다", "처럼", "조차", "까지", "부터도", "대로", "라도", "이며", "인데", "이자"
}

# ✅ 4. 명사 추출 함수 (불용어 제거)
okt = Okt()
def extract_nouns(text):
    return [w for w in okt.nouns(text) if w not in korean_stopwords and len(w) > 1]

# ✅ 숙소명에서 명사 추출 (숙소명 단어 제거용)
def tokenize_hotel_name(hotel_name):
    clean = re.sub(r"[^가-힣]", " ", hotel_name)
    return [w for w in okt.nouns(clean) if len(w) > 1]

# ✅ 5. TF-IDF 분석용 명사 문서 생성
noun_docs = [' '.join(extract_nouns(text)) for text in df["개요"]]
vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split())
tfidf_matrix = vectorizer.fit_transform(noun_docs)
feature_names = vectorizer.get_feature_names_out()

# TF-IDF 특성명(단어 리스트)과 행렬 shape 확인
feature_names.shape
tfidf_matrix.toarray().shape

# TF-IDF 행렬을 DataFrame으로 변환 (행: 문서, 열: 단어)
df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)

# 고유명사 리스트를 하나의 set으로 합치기 (전체 고유명사 집합)
set_proper = set()
for list_proper in df_noun['고유명사'].tolist():
    set_proper = set_proper.union(set(list_proper))

# 고유명사 개수 확인
print(len(set_proper))

# TF-IDF 컬럼명 중 고유명사에 해당하는 단어만 추출
colnames = df_tfidf.columns
target_noun = list(set(colnames).intersection(set_proper))

# 고유명사로 필터링된 컬럼 개수 확인
len(target_noun)

# df_overview: 숙소명 + 개요 포함된 데이터프레임
df_overview.head()

# df_overview와 고유명사 관련 TF-IDF 점수를 합친 통합 테이블 생성
df_merge = pd.concat([df_overview, df_tfidf[target_noun]], axis=1)
df_merge

# 고유명사 점수들의 합이 0보다 큰 경우 → 해당 숙소는 고유명사 포함된 텍스트임
is_target_hotel = df_merge.iloc[:, 2:].sum(axis=1) > 0

# 조건 만족 여부 확인 (True/False 개수)
is_target_hotel.value_counts()

# 고유명사 포함 숙소만 필터링 후 인덱스 리셋
df_merge[is_target_hotel].reset_index(drop=True)

# ✅ TF-IDF 점수 포맷팅 함수 (소수점 3자리로 반올림)
def get_keyword_scores(row, tfidf_row):
    matched_keywords = set_proper.intersection(set(extract_nouns(row["개요"])))
    return {
        keyword: round(tfidf_row.get(keyword, 0.0), 3)
        for keyword in matched_keywords
    }

# ✅ TF-IDF 점수 리스트 생성
tfidf_score_list = []
for idx, row in df_true_hotels.iterrows():
    tfidf_row = df_merge.loc[is_target_hotel].reset_index(drop=True).iloc[idx][target_noun]
    tfidf_score_list.append(get_keyword_scores(row, tfidf_row))

# ✅ 고유명사_TFIDF 컬럼 추가 (딕셔너리 형태)
df_true_hotels["고유명사_TFIDF"] = tfidf_score_list

# ✅ 보기 좋게 문자열로 변환 (예: '부산: 0.135, 해운대: 0.087')
def format_keyword_scores(score_dict):
    return ', '.join([f"{k}: {v:.3f}" for k, v in score_dict.items()])

df_true_hotels["고유명사_TFIDF_문자열"] = df_true_hotels["고유명사_TFIDF"].apply(format_keyword_scores)

# ✅ float64 → float 변환 (np.float64 제거용)
df_true_hotels["고유명사_TFIDF"] = df_true_hotels["고유명사_TFIDF"].apply(
    lambda d: {k: float(v) for k, v in d.items()}
)

# ✅ CSV 저장 (dict 형식 그대로 저장 → eval() 가능)
df_true_hotels[["숙소명", "고유명사_TFIDF"]].to_csv("숙소,개요,키워드.csv", index=False, encoding="cp949")