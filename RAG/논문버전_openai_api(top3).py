# -*- coding: utf-8 -*-
"""ë…¼ë¬¸ë²„ì „_Openai API(TOP3).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_R1Nn2D6qdVXlRTesEDuHcc8RPBSIrWK
"""

!pip install -U langchain langchain-community
!pip install chromadb
!pip install tiktoken

# âœ… 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os
import pandas as pd
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain.chains import LLMChain
from langchain.schema import Document

# âœ… 2. OpenAI API í‚¤
os.environ["OPENAI_API_KEY"] = "sk-..."  # ë³¸ì¸ì˜ í‚¤ë¡œ êµì²´

# âœ… 3. CSV ê¸°ë°˜ ë”•ì…”ë„ˆë¦¬ RDB êµ¬ì„±
rdb_path = "ê´‘ì—­ì‹œ í˜¸í…” ì •ë³´_ê°œìš”ìˆ˜ì •.csv"
df = pd.read_csv(rdb_path)
df = df.drop(columns=[col for col in df.columns if "Unnamed" in col])  # ë¶ˆí•„ìš”í•œ ì—´ ì œê±°
df.fillna("", inplace=True)  # ê²°ì¸¡ê°’ ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬

# ë”•ì…”ë„ˆë¦¬ ë³€í™˜
ìˆ™ì†Œì •ë³´ = {
    row["ëª…ì¹­"]: {
        "ì£¼ì†Œ": row["ì£¼ì†Œ"],
        "ê°œìš”": row["ê°œìš”"],
        "ê°ì‹¤ìœ í˜•": row["ê°ì‹¤ ìœ í˜•"],
        "ì£¼ì°¨ê°€ëŠ¥": row["ì£¼ì°¨ ê°€ëŠ¥"],
        "ë ˆìŠ¤í† ë‘": row["ë ˆìŠ¤í† ë‘"],
        "ë¶€ëŒ€ì‹œì„¤": row["ë¶€ëŒ€ ì‹œì„¤"]
    }
    for _, row in df.iterrows() # ìœ„ ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°ë¥¼ DataFrameì˜ ëª¨ë“  í–‰ì— ëŒ€í•´ ë°˜ë³µì ìœ¼ë¡œ ìƒì„±, iterrowsëŠ” Pandas ë©”ì„œë“œ
}

# âœ… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("VectorDB_ì˜ˆìƒì§ˆì˜.csv").fillna("")

# âœ… ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
docs = []
for _, row in df.iterrows():
    ìˆ™ì†Œëª… = row["ìˆ™ì†Œëª…"]
    ì§ˆë¬¸ë“¤ = [row[f"ì§ˆë¬¸{i}"] for i in range(1, 6) if row[f"ì§ˆë¬¸{i}"].strip()]
    for ì§ˆë¬¸ in ì§ˆë¬¸ë“¤:
        doc = Document(page_content=ì§ˆë¬¸, metadata={"ìˆ™ì†Œëª…": ìˆ™ì†Œëª…})
        docs.append(doc)

# âœ… ë²¡í„°DB ì €ì¥ (í•œë²ˆë§Œ ì‹¤í–‰í•  ê²ƒ)
embedding = OpenAIEmbeddings()
vectordb = Chroma.from_documents(docs, embedding, persist_directory="./chroma_db")
vectordb.persist()
print("âœ… VectorDB ì €ì¥ ì™„ë£Œ: ./chroma_db")

# âœ… 5. ë©”ì‹œì§€ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (1ê°œ ì¶”ì²œ ì „ìš©)
system_template = """
ë‹¹ì‹ ì€ ê´‘ì—­ì‹œ í˜¸í…” ìˆ™ì†Œ ì¶”ì²œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” í›„ë³´ ìˆ™ì†Œ ëª©ë¡ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì½ê³ , ê°€ì¥ ì ì ˆí•œ ìˆ™ì†Œ **1ê°œë§Œ** ì¶”ì²œí•´ ì£¼ì„¸ìš”.
**ë°˜ë“œì‹œ contextì— ì œê³µëœ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨í•´ì•¼ í•˜ë©°, ìˆ™ì†ŒëŠ” ì ˆëŒ€ 1ê°œ ì´ˆê³¼ë¡œ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.**

ì¶œë ¥ ì˜ˆì‹œ (ì •í™•íˆ ì´ í˜•ì‹ì´ì–´ì•¼ í•¨):
1. ê´‘ì•ˆë¦¬ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤
2. í•´ìš´ëŒ€ ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤
3. ì‹œê·¸ë‹ˆì—˜ ë¶€ì‚°
"""

system_msg_one = SystemMessagePromptTemplate.from_template(system_template)
human_msg_one = HumanMessagePromptTemplate.from_template("{context}\n\n[ì‚¬ìš©ì ì§ˆë¬¸]\n{question}")
chat_prompt_one = ChatPromptTemplate.from_messages([system_msg_one, human_msg_one])
llm_one = ChatOpenAI(model_name="gpt-4o", temperature=0.7)
llm_chain = LLMChain(prompt=chat_prompt_one, llm=llm_one)

# âœ… 6. context êµ¬ì„± í•¨ìˆ˜
def build_context(hotel_names, db_dict): # hotel_names: ë²¡í„° ê²€ìƒ‰ì„ í†µí•´ ìœ ì‚¬ ì§ˆë¬¸ì—ì„œ ì¶”ì¶œëœ ìˆ™ì†Œ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    context = ""                         # db_dict: ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ RDB (ì˜ˆ: ìˆ™ì†Œì •ë³´ ë”•ì…”ë„ˆë¦¬), contextëŠ” LLMì—ê²Œ ë„˜ê²¨ì¤„ ë‚´ìš©
    for name in hotel_names: # ì¶”ì²œ ëŒ€ìƒì´ ëœ ìˆ™ì†Œ ì´ë¦„ë“¤ì„ í•˜ë‚˜ì”© ìˆœíšŒ
        info = db_dict.get(name, {}) # ìˆ™ì†Œ ì´ë¦„(name)ì„ í‚¤ë¡œ ë”•ì…”ë„ˆë¦¬ RDBì—ì„œ í•´ë‹¹ ìˆ™ì†Œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¨ë‹¤.
        context += f"[ìˆ™ì†Œëª…] {name}\n[ì£¼ì†Œ] {info.get('ì£¼ì†Œ')}\n[ê°œìš”] {info.get('ê°œìš”')}\n\n" # context êµ¬ì¡°ë¥¼ ë§Œë“¬, LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë°”ê¾¸ëŠ” ê²ƒ
    return context.strip() # ë§ˆì§€ë§‰ì— ë‚¨ì•„ìˆì„ ìˆ˜ ìˆëŠ” ê³µë°±, ì¤„ë°”ê¿ˆ ë“±ì„ ì œê±°í•´ì„œ LLM í”„ë¡¬í”„íŠ¸ì— ê¹”ë”í•œ í˜•íƒœë¡œ ë„˜ê¹€

# âœ… 7. ìµœì¢… ì¶”ì²œ í•¨ìˆ˜
def recommend(user_query, top_k=5): # user_query: ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ì…ë ¥í•œ ìì—°ì–´ ì§ˆë¬¸, top_k: ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ìœ ì‚¬í•œ ì§ˆë¬¸ì„ ëª‡ ê°œê¹Œì§€ ì°¾ì„ ê²ƒì¸ì§€
    docs = vectordb.similarity_search(user_query, k=top_k) # ì´ ì¤„ì€ ì‚¬ìš©ìì˜ ì§ˆì˜ì™€ ê°€ì¥ ìœ ì‚¬í•œ ì§ˆë¬¸ì„ ë²¡í„° ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰
    ì¶”ì²œìˆ™ì†Œë“¤ = list({doc.metadata["ìˆ™ì†Œëª…"] for doc in docs}) # ìœ„ì—ì„œ ê°€ì ¸ì˜¨ Documentë“¤ì—ì„œ ìˆ™ì†Œëª…ë§Œ setìœ¼ë¡œ ë½‘ê³ , ì¤‘ë³µ ì œê±°, ì´ìœ ëŠ” ì¤‘ë³µ ì œê±° + ìˆœì„œ ë³´ì¡´
    context = build_context(ì¶”ì²œìˆ™ì†Œë“¤, ìˆ™ì†Œì •ë³´) # ìœ„ì—ì„œ ì •ì˜í•œ context êµ¬ì„± í•¨ìˆ˜ ì‚¬ìš©
    return llm_chain.run({"context": context, "question": user_query}) # LLM í˜¸ì¶œ, ì „ë‹¬ëœ context + ì‚¬ìš©ì ì§ˆë¬¸ì„ í•©ì³ì„œ GPT ëª¨ë¸ì´ ì‘ë‹µì„ ìƒì„±

# âœ… 8. ì‹¤í–‰ ì˜ˆì‹œ
query = "ê´‘ì•ˆë¦¬ ê·¼ì²˜ì— ê´œì°®ì€ ìˆ™ì†Œ ì¶”ì²œí•´ ì¤„ ìˆ˜ ìˆì–´?"
print("ğŸ¤– AI ì¶”ì²œ ê²°ê³¼:\n")
print(recommend(query)) # í•µì‹¬ í•¨ìˆ˜ recommend(user_query)ë¥¼ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ ì¶œë ¥

import pandas as pd
import re

# âœ… í‰ê°€ì§ˆì˜ ë¶ˆëŸ¬ì˜¤ê¸°
eval_df = pd.read_csv("í‰ê°€ì§ˆì˜_TFIDFìˆœìœ„_ìµœì¢….csv")

# âœ… LLM ì‘ë‹µì—ì„œ ìˆ™ì†Œëª… 3ê°œ ì¶”ì¶œ í•¨ìˆ˜ (í˜•ì‹ ê°•í™” ëŒ€ì‘)
def parse_recommendation(response_text):
    lines = response_text.strip().splitlines()
    result = []
    for line in lines:
        match = re.match(r"\d+\.\s*(.+)", line)
        if match:
            result.append(match.group(1).strip())
    # ë¶€ì¡±í•  ê²½ìš° 'ì¶”ì²œ ì‹¤íŒ¨'ë¡œ ì±„ìš°ê¸°
    while len(result) < 3:
        result.append("ì¶”ì²œ ì‹¤íŒ¨")
    return result[:3]

# âœ… ìë™ í‰ê°€ ì‹¤í–‰
auto_results = []

for idx, row in eval_df.iterrows():
    query = row["ì§ˆì˜"]
    try:
        response = recommend(query)  # LLM í˜¸ì¶œ
        top3 = parse_recommendation(response)
    except Exception as e:
        print(f"[{idx}] ì—ëŸ¬ ë°œìƒ: {e}")
        top3 = ["ì¶”ì²œ ì‹¤íŒ¨", "ì¶”ì²œ ì‹¤íŒ¨", "ì¶”ì²œ ì‹¤íŒ¨"]

    auto_results.append({
        "ì§ˆì˜": query,
        "í¬í•¨í•µì‹¬ì–´": row["í¬í•¨í•µì‹¬ì–´"],
        "í¬í•¨ê°œìˆ˜": row["í¬í•¨ê°œìˆ˜"],
        "ì¶”ì²œ_ìˆ™ì†Œ1": top3[0],
        "ì¶”ì²œ_ìˆ™ì†Œ2": top3[1],
        "ì¶”ì²œ_ìˆ™ì†Œ3": top3[2]
    })

# âœ… ê²°ê³¼ ì €ì¥
auto_df = pd.DataFrame(auto_results)
auto_df.to_csv("í‰ê°€ê²°ê³¼_RAGì¶”ì²œìë™í™”.csv", index=False, encoding="utf-8-sig")